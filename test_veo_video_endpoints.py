#!/usr/bin/env python3
"""
Vertex AI Veo Video Generation - ê°„ë‹¨í•œ ì˜ˆì œ

OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ LiteLLM Proxyë¥¼ í†µí•´ Vertex AI Veo ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

ì‚¬ìš© ì „ í™•ì¸ì‚¬í•­:
1. LiteLLM Proxy ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•©ë‹ˆë‹¤ (ê¸°ë³¸: http://localhost:4000)
2. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜: pip install openai
"""

import os
import sys
from openai import OpenAI


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ì½ê¸° (ì„ íƒì‚¬í•­)
    proxy_url = os.getenv("LITELLM_PROXY_URL", "http://localhost:4000")
    api_key = os.getenv("LITELLM_API_KEY", "sk-1234")
    
    print(f"ğŸ”— Proxy URL: {proxy_url}")
    print(f"ğŸ”‘ API Key: {api_key[:10]}...")
    print()
    
    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (LiteLLM Proxy ì‚¬ìš©)
    client = OpenAI(
        api_key=api_key,
        base_url=f"{proxy_url.rstrip('/')}/v1",
    )
    
    try:
        # ë¹„ë””ì˜¤ ìƒì„±
        print("ğŸ¬ ë¹„ë””ì˜¤ ìƒì„± ì¤‘...")
        video = client.videos.create(
            model="veo3-0",
            prompt="A beautiful sunset over the ocean with gentle waves",
            seconds="5",
        )
        
        print(f"âœ… ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
        print(f"   Video ID: {video.id}")
        print(f"   Status: {video.status}")
        
        # ì—ëŸ¬ ì •ë³´ ì¶œë ¥
        if video.status == "failed":
            if hasattr(video, 'error') and video.error:
                error = video.error
                if isinstance(error, dict):
                    print(f"   âŒ ì—ëŸ¬: {error.get('message', 'Unknown error')}")
                    if 'code' in error:
                        print(f"   ì—ëŸ¬ ì½”ë“œ: {error['code']}")
                    if 'details' in error:
                        print(f"   ìƒì„¸ ì •ë³´: {error['details']}")
                else:
                    print(f"   âŒ ì—ëŸ¬: {error}")
            else:
                print(f"   âŒ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨ (ì—ëŸ¬ ì •ë³´ ì—†ìŒ)")
            
            # ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
            if hasattr(video, '_hidden_params') and video._hidden_params:
                hidden = video._hidden_params
                if 'debug_response' in hidden:
                    print(f"   ë””ë²„ê·¸ ì‘ë‹µ: {hidden['debug_response']}")
        
        # ë¹„ìš© ì •ë³´ ì¶œë ¥
        if hasattr(video, 'usage') and video.usage:
            usage = video.usage
            if isinstance(usage, dict) and "duration_seconds" in usage:
                duration = usage["duration_seconds"]
                print(f"   ë¹„ë””ì˜¤ ê¸¸ì´: {duration}ì´ˆ")
                # veo3-0 ê°€ê²©: $0.10/ì´ˆ
                estimated_cost = duration * 0.10
                print(f"   ì˜ˆìƒ ë¹„ìš©: ${estimated_cost:.4f}")
    
    except Exception as e:
        error_msg = str(e)
        if "Connection refused" in error_msg or "Connection error" in error_msg:
            print(f"âŒ ì—°ê²° ì˜¤ë¥˜: LiteLLM Proxy ì„œë²„ê°€ ì‹¤í–‰ë˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            print(f"   Proxy URL: {proxy_url}")
            print(f"   ì„œë²„ë¥¼ ì‹œì‘í•˜ë ¤ë©´: litellm --config config.yaml")
            sys.exit(1)
        else:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)


if __name__ == "__main__":
    main()
